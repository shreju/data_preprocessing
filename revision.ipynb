{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsg9vuWUdlLWWuZyqonmEU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreju/data_preprocessing/blob/main/revision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "67zTuglaGKI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9279bdcd-8e06-4241-b5bb-012749a8f595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset\n",
            "   Country   Age   Salary Purchased\n",
            "0   France  44.0  72000.0        No\n",
            "1    Spain  27.0  48000.0       Yes\n",
            "2  Germany  30.0  54000.0        No\n",
            "3    Spain  38.0  61000.0        No\n",
            "4  Germany  40.0      NaN       Yes\n",
            "5   France  35.0  58000.0       Yes\n",
            "6    Spain   NaN  52000.0        No\n",
            "7   France  48.0  79000.0       Yes\n",
            "8  Germany  50.0  83000.0        No\n",
            "9   France  37.0  67000.0       Yes\n",
            "\n",
            "independent varaible\n",
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "\n",
            "dependent variable\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n",
            "\n",
            "filling the missing values\n",
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "\n",
            "encoding the independent variable\n",
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n",
            "\n",
            "encoding the dependent variable\n",
            "[0 1 0 0 1 1 0 1 0 1]\n",
            "\n",
            "training and testing the data set \n",
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n",
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes']\n",
            "['No' 'Yes']\n",
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n",
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ],
      "source": [
        "# importing the libraies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# importing the dataset\n",
        "dataset = pd.read_csv('Data1.csv')\n",
        "print(\"dataset\")\n",
        "print(dataset)\n",
        "\n",
        "x = dataset.iloc[:,:-1].values # independent variable\n",
        "y = dataset.iloc[:,-1].values # dependent variable\n",
        "print()\n",
        "print(\"independent varaible\")\n",
        "print(x)\n",
        "\n",
        "print()\n",
        "print(\"dependent variable\")\n",
        "print(y)\n",
        "\n",
        "# filling the missing values\n",
        "imputer = SimpleImputer(missing_values = np.NaN, strategy = 'mean')\n",
        "imputer.fit(x[:,1:3])\n",
        "x[:,1:3] = imputer.transform(x[:,1:3])\n",
        "print()\n",
        "print(\"filling the missing values\")\n",
        "print(x)\n",
        "\n",
        "# encoding the independent variable\n",
        "CT = ColumnTransformer(transformers=[('encoder', OneHotEncoder(),[0])], remainder = 'passthrough')\n",
        "x = np.array(CT.fit_transform(x))\n",
        "print()\n",
        "print(\"encoding the independent variable\")\n",
        "print(x)\n",
        "\n",
        "# encoding the dependent variable\n",
        "le = LabelEncoder()\n",
        "Y = np.array(le.fit_transform(y))\n",
        "print()\n",
        "print(\"encoding the dependent variable\")\n",
        "print(Y)\n",
        "\n",
        "# splitting train and test data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=2, random_state=1)\n",
        "print()\n",
        "print(\"training and testing the data set \")\n",
        "print(x_train)\n",
        "print(x_test)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "# feature scalling\n",
        "sc = StandardScaler()\n",
        "x_train[:,3:] = sc.fit_transform(x_train[:,3:])\n",
        "x_test[:,3:] = sc.transform(x_test[:,3:])\n",
        "print(x_train)\n",
        "print(x_test)\n",
        "\n"
      ]
    }
  ]
}